{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling on Social Media posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources: \n",
    "1. https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24\n",
    "2. https://nbviewer.jupyter.org/github/bmabey/pyLDAvis/blob/master/notebooks/pyLDAvis_overview.ipynb#topic=0&lambda=1&term=\n",
    "3. https://pyldavis.readthedocs.io/en/latest/modules/API.html#pyLDAvis.save_html\n",
    "4. https://towardsdatascience.com/nlp-embedding-techniques-51b7e6ec9f92"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: What are the common topics being discussed by the netizens in Twitter on the Presidential Candidates?\n",
    "\n",
    "## Scope:\n",
    "- Presidential Candidates\n",
    "- Twitter\n",
    "- Past few days\n",
    "\n",
    "## Steps:\n",
    "1. Gather data based on the set parameters\n",
    "2. Load Data\n",
    "3. Data Enggineering (process and clean data)\n",
    "    1. Remove special characters\n",
    "    2. Remove usernames\n",
    "    3. Remove stop words\n",
    "4. Modeling\n",
    "    1. Choose the methods\n",
    "    2. Choose the parameters of that method (e.g. number of topics)\n",
    "    3. Run the model on the dataset\n",
    "    4. Save\n",
    "    5. Visualize\n",
    "5. Analyze Results\n",
    "\n",
    "## Code\n",
    "\n",
    "## Test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Gather data\n",
    "\n",
    "You can use tools available online to extract/gather data from social media platforms\n",
    "- Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-docx in /Users/isabelsaludares/miniconda3/lib/python3.7/site-packages (0.8.11)\r\n",
      "Requirement already satisfied: lxml>=2.3.2 in /Users/isabelsaludares/miniconda3/lib/python3.7/site-packages (from python-docx) (4.5.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IMPORTANT ANNOUNCEMENT',\n",
       " 'Ini-launch natin noong Miyerkules ang Bayanihan E-konsulta. Sobrang salamat sa lahat ng nag-volunteer—mga doktor, mga tumatao sa call center—pati rin sa mga simpleng messages of support. Overwhelmingly positive ang naging response sa initiative natin.',\n",
       " 'Sobrang overwhelming ang support, at sobrang overwhelming din ang dami ng requests na pinaabot sa atin. Patunay ito na kailangang natin ng ganitong uri ng serbisyo.',\n",
       " 'Hindi kami nagpapigil kahit ang daming limitasyon, at kailangan namin ngayon ng kaunting oras para habulin at tugunan muna ang lahat ng pumasok na request.',\n",
       " 'Kaya, despite our reluctance to do so, tomorrow, Monday, April 12, we will not be receiving new requests first.',\n",
       " 'Isang araw lang po ito. Kailangan lang po namin ng panahon para ma integrate na yung external volunteers at maayos lahat na technical issues at backlogs. Hindi po namin inaasahan ang dagsa ng nagkukunsulta kaya kailangan lalong paghusayan ang ating platform at process flow.',\n",
       " 'Magreresume ulit tayo ng pagtanggap ng bagong requests 7 AM on Tuesday, April 13.',\n",
       " 'Humihingi ako ng paumanhin at pang-unawa sa lahat. Binanggit ko ito before we launched—bitin tayo sa resources, at malinaw na sobrang dami talaga ng taong kailangang kumonsulta sa doktor remotely.',\n",
       " 'Gusto pa nating magpatuloy ang programa, at makatulong sa mas marami pang tao, kaya we need a day to work through our backlogs with the help of our external volunteers and make our system even more responsive, including fixing all technical issues.',\n",
       " 'Naiimagine ko nga—kung kami na nag-o-augment lang ng capacity ganito na ang pagka-overwhelm, paano pa kaya ‘yung mga healthcare workers sa mga ospital? Tuloy ang prayers natin para sa kanila, sa COVID patients, pati na rin gratitude sa lahat ng tumutulong sa ating volunteers.',\n",
       " 'Salamat sa pag-unawa! Resume po ulit ang Bayanihan E-konsulta natin sa Tuesday, 7am.',\n",
       " '24 hours after we posted our call for medical and non medical volunteers, more than 2,300 volunteers signed up already!! We are overwhelmed and inspired by everyone’s kindness and desire to help. ',\n",
       " 'We are temporarily closing sign-ups as we bring everyone on board for our rollout.',\n",
       " 'Since our program is meant to fill in gaps, we expect it to be evolving and we want to manage it in the best way we can. ',\n",
       " 'To those who have been planning to join, please stay tuned for further announcements. ',\n",
       " 'Maraming salamat ulit sa lahat!',\n",
       " 'Our Swab Cabs went back to Malabon this morning. Good sign that more people got themselves tested. ',\n",
       " 'Thank you to LGU Malabon, to our partners—and especially to the BHERTs who did a great job in the immediate contact tracing.',\n",
       " 'The good thing about swab antigen tests is results are out in 15 minutes. Under our initiative, whenever there is an individual who tests positive, an ambulance on standby would bring him/her directly to a pre designated isolation center. Then, contact tracing immediately ensues.',\n",
       " 'Of the 711 who were tested today, 46 turned out positive. This brings to 80 the total number of those who tested positive in the 2 days of our Swab Cab Operations in Malabon. Those who tested negative but are displaying symptoms will undergo a confirmatory rt pcr test tomorrow.',\n",
       " 'Thank you to our team, including our volunteer swabbers, to Mayor Len Oreta and LGU Malabon, UBE Express, Kaya Natin Movement, and to our Angat Buhay partners for working with us in this initiative.',\n",
       " 'We need health professionals and other volunteers for an initiative to help outpatient cases in the NCR Plus Bubble and complement efforts to decongest our hospitals.',\n",
       " 'To sign up:',\n",
       " 'Volunteer doctors - http://bit.ly/e-konsulta_doctors',\n",
       " 'Call center volunteers - ',\n",
       " 'Resulta ito ng pag konsulta namin buong holy week sa mga doktor at eksperto kung papaano pa kami makakatulong, sa gitna ng mga nababasa natin na mga messages, kuwento, at mga post sa social media - mga namatayan, naghahanap ng ospital, naghahanap ng makakausap na doktor.',\n",
       " 'With the help of volunteers, nag-iisip kaming maglunsad ng inisyatiba na hindi lang makakatulong sa mga mahihirap na walang pambayad sa doktor, pero sana ay makatulong din sa pag-iwas ng lalong pagdami ng mga taong pumupunta sa ospital.',\n",
       " 'Marami kaming limitasyon, pero gaya ng lagi, ang hangarin natin ay makatulong sa abot ng ating makakaya - kung makakapagligtas ng kahit isang buhay, at mapapagaan ang dala ng ating mga kababayan.',\n",
       " 'So here we are now. Nananawagan kami para sa mga volunteers - doctors, health professionals, and others who are willing to help. Sa mga susunod na araw, we’ll share more details to the public. ',\n",
       " 'If you can, we hope you will join us.',\n",
       " 'Kakayanin natin ito. Ingat sa lahat.',\n",
       " \"Happy Easter, everyone. Some suggestions on the announced PDITR scheme from yesterday's presscon:\",\n",
       " '1. PREVENTION',\n",
       " 'a. To ensure its effectiveness, extension of the ECQ must be accompanied by clear, verifiable objectives and time bound scorecards.',\n",
       " '1. PREVENTION — b. Budget for ayuda, and its effective and fair deployment, will make people be more willing to comply with lockdowns. Kasi the only reason na nagpipilit silang lumabas is wala silang makakain pag di sila nagtrabaho.',\n",
       " '1. PREVENTION — c. Efficient border control to contain the virus. Issue and disseminate a comprehensive list of essential goods to inform the public what can and cannot be delivered, and lessen traffic in checkpoints. Fast lanes, too, in checkpoints for faster deliveries.',\n",
       " '2. TESTING',\n",
       " 'a.  Aside from just testing those with symptoms or being contact traced, do mass testing in areas where transmission is very high. Target testing numbers according to active cases per capita. Support LGUs without enough funds to conduct testing of this magnitude.',\n",
       " '2. TESTING — b. Incentivize people to have themselves tested.',\n",
       " 'c. Use antigen testing to complement RT PCR, so that results are immediate and contact tracing can be done immediately. RT PCR  for confirmatory testing of those who tested negative but with symptoms and exposure.',\n",
       " '2. TESTING — d. Number of tests to be conducted should be aimed at reducing positivity rate to less than 5%. As of April 2, we would need a minimum of 191,491 unique individual tests per day, ...',\n",
       " '... according to the 7-day average of testing data, to lower the positivity rate to 5%. This assumes that everyone tested will turn out negative – which is almost impossible. This number may serve as a minimum target to reach in terms of testing.',\n",
       " '2. TESTING — e. Make sure that we have mobile testing sites aside from stationary ones so that testing is accessible to all. These mobile testing sites may be deployed to areas where positive individuals are concentrated...',\n",
       " \".. They will allow residents of that area to be tested without going far from their residences and lessening the risk of exposure to others. We're running our Swab Cab pilots-- baka puwedeng gawing model kung gustong i-scale up ng gobyerno.\",\n",
       " 'f. Free testing.',\n",
       " '3. TRACING',\n",
       " 'a. Utilize BHERTs to do immediate contact tracing once antigen test results become available.',\n",
       " 'b. Do immediate antigen testing to those who were contact traced.',\n",
       " '3. TRACING — c. Use Staysafe app or whatever is the standard app to unify or centralize contact tracing. All LGUs that already have different contact tracing apps should be connected to Staysafe. ',\n",
       " 'd. Have a centralized repository of contact tracing data.',\n",
       " '3. TRACING — e. Set goals. Before, Mayor Magalong said ideal is 1:37. I understand, currently, we’re just accomplishing 1:3, even less in NCR.',\n",
       " '4. ISOLATION',\n",
       " 'a. Make sure that we have enough well-equipped, well-ventilated, comfortable isolation centers to handle those who will test positive with no capacity to self-isolate at home.',\n",
       " '4. ISOLATION — b. For the vulnerable, make sure that there is support for the family when one is in isolation. Ito usually ang dahilan kung bakit may resistance sa isolation.',\n",
       " '4. ISOLATION — c. For those with capacity to self isolate at home, make sure medical help is available - doctors to call, COVID kits, basic medical equipment in brgy health centers that they have immediate access to, ambulance available anytime that people don’t have to pay for.',\n",
       " '5. TREATMENT',\n",
       " 'a. Site and hotline that would be available 24/7 for people needing hospitalizations, quarantine/isolation areas, etc. Updates should be real time.',\n",
       " 'b. Set up field hospitals strategically. Additional number of beds should be based on needs assessment.',\n",
       " '5. TREATMENT— c. Hire more doctors, nurses, and other health personnel with compensation commensurate to their efforts and sacrifices.',\n",
       " 'd. If necessary, recruit from provinces with low transmission rates but offer attractive packages, fly them to Manila, give free accommodations.',\n",
       " '5. TREATMENT — e. Stack up on the necessary medicines and medical equipment that are needed in treating Covid 19 patients.',\n",
       " '6. REINTEGRATION',\n",
       " 'a. Vaccine rollout – more aggressive communications campaign to improve vaccine trust',\n",
       " 'b. Assist LGUs for more efficient vaccine rollout. Sana ma-expand at ma strengthen-- supply chain, logistics, etc. Private sector participation should be encouraged, maximized',\n",
       " '6. REINTEGRATION — c. Aim for herd immunity by end of 2021. More than 70% of population vaccinated.',\n",
       " 'd. Ayuda for businesses, those who lost jobs, those who suddenly became underemployed, livelihood assistance, etc',\n",
       " '7. WHAT INDIVIDUALS CAN DO',\n",
       " 'a. Huwag nang lumabas, please, unless absolutely necessary.',\n",
       " 'b. Kung lalabas: Face mask at face shield, hugas ng kamay. Physical distancing palagi.',\n",
       " 'c. Monitor your symptoms. Kung masama ang pakiramdam, mag-isolate muna.',\n",
       " '7. WHAT INDIVIDUALS CAN DO — d. Kung may access sa testing, magpa-test.',\n",
       " 'e. Kung maaari, magpalista na sa bakuna ng LGU. ',\n",
       " 'f. Iwasang kumain nang may kasabay.',\n",
       " '7. WHAT INDIVIDUALS CAN DO — g. Kung may kailangan itakbo sa ospital tumawag muna sa One Hospital Command Center: 0919-977-3333, 0915-777-7777, 02 886 505 00',\n",
       " '7. WHAT INDIVIDUALS CAN DO — h. Yung mga kaya nating maiambag para maisakatuparan ang suggestions sa itaas, kahit pa gaano kaliit, will be most welcome. Lahat na iba pang suggestions ay welcome din para mapag aralan.',\n",
       " '[A] NOW LIVE: Interreligious prayer service – ',\n",
       " '[A] LIVE ON FB: Easter Mass for healing and remembrance',\n",
       " 'Join us at: ',\n",
       " 'Inviting everyone to join us tomorrow, Easter Sunday, for an online gathering so we can all pray together as one community.',\n",
       " 'There will be an Easter Mass to be officiated by Fr Tito Caluag at 10.30. But we will start streaming at 10.20 for the Holy Rosary. Right after the Mass, we will have an interreligious prayer service, where leaders of the different religious denominations will lead us in prayer.',\n",
       " 'Let us pray as one community for the healing of the sick and let us remember all those we lost during the pandemic.',\n",
       " 'Please invite your friends and family to join us. These will be streamed live at the VP Leni Robredo and ',\n",
       " '@KayaNatinPH',\n",
       " ' FB pages.',\n",
       " 'Notes from our Swab Cab roll out:',\n",
       " '1. LGU Malabon provided medical teams for 3 swab cabs;',\n",
       " '2. BHERTs in 5 brgys covered identified who needed to be swabbed after house-to-house assessment, took charge of orientation and contact tracing;',\n",
       " '3. 3 teams from OVP were in testing areas;',\n",
       " '4. We were ready to test 1,500 people. But BHERTs had a hard time convincing people. Most of those who refused were worried they would be required to isolate if found positive. We were only able to test 502;',\n",
       " '5. 34 were positive. 12 who tested negative displaying symptoms;',\n",
       " '6. Per agreed protocols, they will immediately be isolated and confirmatory RT PCR tests will be conducted tomorrow (DOH announced just now that those who tested positive through antigen tests will be counted in the tally of Covid 19 cases. So we will need to meet again on this);',\n",
       " '7. We are setting up a new isolation facility with LGU Malabon to accommodate those who tested positive and are not qualified to do home isolation. Hindi pa po ito tapos. Inaayos pa until now. Ang kailangan na tulong now, more mattresses and electric fans;',\n",
       " '8. We already gave COVID 19 Safety Kits to all those swabbed earlier. Tomorrow, we will be providing food packs to families of the Covid -positive patients who needed to isolate;',\n",
       " '9. The resistance to undergo swab testing is real. People are worried that if they test positive and are required to isolate, they will not be able to work and their families might go hungry. Delikado ito.',\n",
       " 'Since there are many asymptomatic patients / displaying very mild symptoms, we will not be able to control transmission with many of them still going around, possibly infecting others. So we need to seriously think how we can incentivize people to convince them to get tested.',\n",
       " 'One way is to give cash assistance equivalent to at least the minimum wage for every day that they are not able to work because they are isolated. Yung problema namin sa OVP, wala kaming resources for this kaya kailangan talagang maghanap ng paraan;',\n",
       " '10. Having mobile testing centers where people can have themselves tested for free will greatly help control the transmission of the virus. This is easily replicable. We will post tomorrow what are needed to operationalize something like this in your own communities.',\n",
       " 'So far, maayos yung first hour ng ating Swab Cab operations. Bawat test ay nag aaverage lang ng 2 minutes. Nagpapasalamat tayo sa mga BHERTs ng bawat barangay sa napakaayos na proseso.',\n",
       " 'During our preparatory meetings, we requested na paunti unti lang yung pupunta sa waiting area para walang pagtitipon ng maraming tao. Mahusay ang naging execution ng mga barangay. Maraming salamat sa inyo.',\n",
       " 'Nag deploy tayo ng 3 SWAB CABS (na umunlad to buses) for 5 barangays ngayong araw.',\n",
       " 'Maraming salamat sa LGU-Malabon, UBE Express, at Kaya Natin Movement for making this possible.',\n",
       " 'Our SWAB CABSs are ready for our first day in Malabon.',\n",
       " 'SWAB CABS* (good morning)',\n",
       " 'Preparing our SWAB CAB and retroffiting it to make sure all health and safety protocols are followed for tomorrow’s rollout in Malabon. Thank you to Dr Popo Soller for guiding us and to the Health Care Professionals Alliance Against Covid 19 for the very important inputs.',\n",
       " 'Join us on our Facebook page, VP Leni Robredo (https://facebook.com/VPLeniRobredoPH',\n",
       " ') this afternoon as we introduce our initiative, alongside our partners.',\n",
       " 'After our announcement last night, some doctors reached out with important suggestions to make our Swab Cab initiative more effective.',\n",
       " 'Thanks to well-meaning experts for the recommendations. We’re meeting with them, and will update once we’ve incorporated their suggestions.',\n",
       " 'Another Sunday suggestion re TESTING: Increase testing but let’s make it more targeted. ',\n",
       " '1. If you look at this table, there were 6,936 positive cases on March 26. But DOH actually reported more than 9,000 to include the previous positive cases which they have not yet reported;',\n",
       " '2. Using just the 6,936 positive cases, we are recommending the minimum number of tests that should be conducted per day per region. Better sana if by LGU but there is no disaggregated data available per town/city/province on the tests conducted;',\n",
       " '3. Right now, we’re conducting between 30,000-50,000 tests per day all over the country. But if you look at the table, the positivity rates for some regions are so high that the number of tests we are conducting are no longer enough;',\n",
       " '4. WHO standard is positivity rate should be less than 5%. We need to have that as our target. Last column in the table shows our recommended number of tests per day per region, based on the March 26 numbers. We will do this on a daily basis as the reports come in;',\n",
       " '5. Based on the table, in NCR alone, we need about 90,000 tests per day. Here, positivity rate is 20.17%. This means for every 5 tests, 1 turns out positive;',\n",
       " '6. While absolute numbers in Cagayan Valley are small compared to NCR, per capita numbers are high; positivity rate highest at 28.94%. This means that for every 4 being tested, more than one is Covid-positive. A minimum of 3,860 tests per day is needed for 5% positivity rate;',\n",
       " '7. Of course, these numbers will adjust depending on the results of the surveillance testing. But we need to do it now.',\n",
       " 'We’re launching SWAB CAB, a mobile testing program which will do mass surveillance testing in communities where transmission is very high.  Pilot area is Malabon. Thank you to LGU Malabon, Ube Express and Kaya Natin Movement for the partnership.',\n",
       " 'We will using FDA-approved antigen test with high efficacy rate. First batch of tests will be from privately-donated funds. But our office is ready to appropriate funds for more if urgently needed.',\n",
       " '*be using',\n",
       " 'We have been working on this project last week to help combat the surge. Thanks to our partners for making this possible.',\n",
       " 'Hopefully this will prevent those asymptomatic and who have not yet been tested from further transmitting the virus.',\n",
       " 'All those who will test positive will already be isolated and subjected to RT PCR test.',\n",
       " 'Existing RT PCR tests usually are for those with symptoms or have been contact traced. We will do antigen testing to target those without symptoms and no known exposure to Covid positive cases.',\n",
       " 'Sunday suggestions. ',\n",
       " '1. 7,999 cases at 15.7% positivity rate and 2.03 reproduction number. I hope we are doing massive testing, contact tracing and isolation specially in areas that are on surgical lockdowns. Hindi na puwede yung previous target na 30,000-40,000 tests per day;',\n",
       " '2. We need to improve our vaccine rollout.  Per DOH numbers, for the period March 1-17, 269,583 health frontliners were innoculated. That is just 23.95%. At this rate, we are only averaging 15,857 per day;',\n",
       " '3. Govt target is herd immunity by the end of the year. Herd immunity is 70% of the population. 70% of 105M people is 73,500,000. If we have about 286 remaining days in 2021, we should innoculate 256,993 people per day. We are so far off the target at the rate we are going now;',\n",
       " '4. Sec Duque said we can’t rush innoculating our health frontliners kasi mauubos tao sa ospital kung sabay sabay sila tuturukan. ',\n",
       " 'Our ask since last year: prepare deployment plan, treat it as a logistics problem, identify and train vaccinators, prepare large vaccination centers',\n",
       " 'Totoo na problema pa ang supply. Pero yung konting supply na dumating, hindi pa natin ma deploy with speed and dispatch. Let us assess where the bottlenecks are. 1M palang supply natin, pero in 17 days hindi pa nga tayo naka 50% utilization, papaano na kung 70M na yung available?',\n",
       " '5. Private sector is a big help. Sana let us not over regulate. Let us not make it difficult for private companies to participate. Wala sigurong problema for bigger companies. But for smaller businesses who only want to make their employees safe, huwag na masyadong pahirapan pa.',\n",
       " 'There are best practices, like Indonesia and India. Okay to have rules and parameters, pero don’t make it too difficult. For every Filipino who gets the vaccine, the entire community benefits. ',\n",
       " 'Same for LGUs—capacitate those who want to invest in vaccines for their constituents;',\n",
       " '6. “Sumunod nalang kasi kayo”. Madali lang ito sabihin if you are speaking from a position of privilege. Pero kung wala ka nang ipapakain sa pamilya mo, lalabas ka pa din kahit nakakatakot.',\n",
       " 'Stimulus package, please. Ayuda para sa mga nawalan ng trabaho at kita',\n",
       " 'Hindi sapat yung binigay natin dati. Magandang halimbawa dito ang Malaysia. Naging sobrang masama din yung cases nila when they started to reopen. But they were able to arrest the situation. Maraming ginawa to achieve this. Isa doon, 6 nang stimulus packages yung naibigay nila;',\n",
       " '7. Our problem at hand is huge. We have to deal with this collectively. Huwag sana masamain ang suggestions.',\n",
       " 'inoculating*',\n",
       " 'inoculate*',\n",
       " 'inoculated*',\n",
       " 'A year into lockdown and we’ve weathered through so much: thousands of deaths and cases, millions of jobs and chances lost, many moments of confusion, uncertainty, and fears. ',\n",
       " 'Amid all these, we’ve counted on frontliners to lead us forward.',\n",
       " 'We owe so much to our valiant health frontliners, who are closest to the dangers of COVID-19 every day. Their courage and their heart reverberate across hospitals and health centers, in testing centers, in barangay clinics and down at the communities.',\n",
       " 'Over the past year, we have lost hundreds of our medical frontliners in this fight. Grateful that their community carries on despite the sacrifices it calls for—so that we can reach the safer, healthier nation we aspire for.',\n",
       " 'Thankful, too, to our LGUs for showing us what can be done in unprecedented times—swift delivery of relief and services, support for medical workers, tech-based approaches for contact tracing and information drive, and other efforts to uplift the community.',\n",
       " 'It’s inspiring that many of our leaders and fellow workers in LGUs stepped up to address many needs despite limitations. Their ingenuity and compassion are glimmers of hope that leadership is possible amid the crisis we face.',\n",
       " 'We also thank our soldiers and police officers who stay true to their calling, and whose help has been invaluable in delivering assistance to communities, and all Filipino workers who provide us essential services despite the dangers.',\n",
       " 'Sa ating mga frontliners: Maraming, maraming salamat sa serbisyo at sakripisyo. Isang taon na, at alam kong nakakapagod. Alam kong nakakaubos magbigay ng sarili, lalo na’t matindi pa rin ang ating laban. Pero sa inyong pagpupursige kami humuhugot ng lakas.',\n",
       " 'Amid the many problems we still have to solve, as we move forward as a nation, we find hope in you. I and the OVP are committed to continue supporting you. Sama-sama tayo sa pagsulong sa pangarap na mapagtagumpayan ang laban na ito.',\n",
       " '[A] VP Leni Robredo now delivering her statement on the PET decision to dismiss the electoral protest. WATCH: ',\n",
       " 'Visiting a sewing community we are helping in Bgy Sta Ana, Taytay, Rizal.',\n",
       " 'Cardona, Rizal this morning to visit the communities we are helping.',\n",
       " 'Early Sat morning start here in Libmanan, Camarines Sur for the inauguration of our Shared Service Facility for farmers. So proud of the transformation of our partner farmers like Robert here who are already entrepreneurs.',\n",
       " 'This came into fruition because of our partnership with DTI, DA, DAR, DOST, Metro Naga Chamber of Commerce and Industry. There are 10 of these in the province. When govt agencies and private orgs collaborate and do not work in silos, there is no much that can be achieved.',\n",
       " '*so',\n",
       " '[A] Vice President Leni Robredo on the termination of the 1989 UP-DND Accord: “The unilateral scrapping of the decades-old Accord sends the opposite message: That under this administration, anyone, anywhere, at anytime, is fair game.”',\n",
       " 'Full text here: ',\n",
       " '2021 na, ang trolls mahilig pa rin mag-recycle ng kasinungalingan the picture was taken in March 2016. The slippers were given away by Mayor Joy Belmonte at her birthday event, in support of our VP bid.',\n",
       " 'Throwback facts from years ago: https://newsinfo.inquirer.net/1056283/fake-news-robredo-slippers-found-at-abandoned-communist-camp']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fname='./data/nlp/survey/RWA survey - Responses.xlsx'\n",
    "# df=pd.read_excel(fname)\n",
    "\n",
    "import docx\n",
    "\n",
    "doc = docx.Document('./data/nlp/socmed/Leni Robredo 2021 tweets (4-12-21).docx')\n",
    "docs = [p.text for p in doc.paragraphs if p.text]\n",
    "\n",
    "\n",
    "docs_1 = []\n",
    "for p in doc.paragraphs:\n",
    "    if p.text:\n",
    "        docs_1.append(p.text)\n",
    "#docs\n",
    "\n",
    "docs_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## library of functions on regular expressions\n",
    "import re\n",
    "#regex : regular expressions\n",
    "\n",
    "## This removes the word that starts with '@'\n",
    "twts = [re.sub(r'(\\s)@\\w+', r'', a) for a in docs]\n",
    "\n",
    "\n",
    "## beautiful soup -- parsing HTML formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IMPORTANT ANNOUNCEMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ini-launch natin noong Miyerkules ang Bayaniha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sobrang overwhelming ang support, at sobrang o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hindi kami nagpapigil kahit ang daming limitas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kaya, despite our reluctance to do so, tomorro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>*so</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>[A] Vice President Leni Robredo on the termina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Full text here:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>2021 na, ang trolls mahilig pa rin mag-recycle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>Throwback facts from years ago: https://newsin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     0\n",
       "0                               IMPORTANT ANNOUNCEMENT\n",
       "1    Ini-launch natin noong Miyerkules ang Bayaniha...\n",
       "2    Sobrang overwhelming ang support, at sobrang o...\n",
       "3    Hindi kami nagpapigil kahit ang daming limitas...\n",
       "4    Kaya, despite our reluctance to do so, tomorro...\n",
       "..                                                 ...\n",
       "154                                                *so\n",
       "155  [A] Vice President Leni Robredo on the termina...\n",
       "156                                   Full text here: \n",
       "157  2021 na, ang trolls mahilig pa rin mag-recycle...\n",
       "158  Throwback facts from years ago: https://newsin...\n",
       "\n",
       "[159 rows x 1 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twts = pd.DataFrame(twts)\n",
    "twts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve desired column (for feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>important announcement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ini-launch natin noong miyerkules ang bayaniha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sobrang overwhelming ang support, at sobrang o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hindi kami nagpapigil kahit ang daming limitas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kaya, despite our reluctance to do so, tomorro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>*so</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>[a] vice president leni robredo on the termina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>full text here:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>2021 na, ang trolls mahilig pa rin mag-recycle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>throwback facts from years ago: https://newsin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Comments\n",
       "0                               important announcement\n",
       "1    ini-launch natin noong miyerkules ang bayaniha...\n",
       "2    sobrang overwhelming ang support, at sobrang o...\n",
       "3    hindi kami nagpapigil kahit ang daming limitas...\n",
       "4    kaya, despite our reluctance to do so, tomorro...\n",
       "..                                                 ...\n",
       "154                                                *so\n",
       "155  [a] vice president leni robredo on the termina...\n",
       "156                                   full text here: \n",
       "157  2021 na, ang trolls mahilig pa rin mag-recycle...\n",
       "158  throwback facts from years ago: https://newsin...\n",
       "\n",
       "[159 rows x 1 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## This retrieves the column for processing\n",
    "\n",
    "'''\n",
    "Twitter dataset: this actually only has comments \n",
    "therefore based on the dataframe generated\n",
    "For other datasets: identify the desired column\n",
    "\n",
    "This is the first column so use: twts[0]\n",
    "Rename the column title with the correct name: Comments\n",
    "'''\n",
    "l_dataset=pd.DataFrame({'Comments':twts[0].str.lower()}) # the dataset that we need\n",
    "l_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. NLP\n",
    "## 4.1. Load NLP libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /Users/isabelsaludares/miniconda3/lib/python3.7/site-packages (3.8.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/isabelsaludares/miniconda3/lib/python3.7/site-packages (from gensim) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /Users/isabelsaludares/miniconda3/lib/python3.7/site-packages (from gensim) (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /Users/isabelsaludares/miniconda3/lib/python3.7/site-packages (from gensim) (1.21.3)\n",
      "Requirement already satisfied: six>=1.5.0 in /Users/isabelsaludares/miniconda3/lib/python3.7/site-packages (from gensim) (1.15.0)\n",
      "Requirement already satisfied: boto in /Users/isabelsaludares/miniconda3/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\n",
      "Requirement already satisfied: requests in /Users/isabelsaludares/miniconda3/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.22.0)\n",
      "Requirement already satisfied: boto3 in /Users/isabelsaludares/miniconda3/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (1.14.35)\n",
      "Requirement already satisfied: botocore<1.18.0,>=1.17.35 in /Users/isabelsaludares/miniconda3/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (1.17.35)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /Users/isabelsaludares/miniconda3/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /Users/isabelsaludares/miniconda3/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.10.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/isabelsaludares/miniconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (1.25.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/isabelsaludares/miniconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/isabelsaludares/miniconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/isabelsaludares/miniconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2.8)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /Users/isabelsaludares/miniconda3/lib/python3.7/site-packages (from botocore<1.18.0,>=1.17.35->boto3->smart-open>=1.8.1->gensim) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/isabelsaludares/miniconda3/lib/python3.7/site-packages (from botocore<1.18.0,>=1.17.35->boto3->smart-open>=1.8.1->gensim) (2.8.1)\n",
      "Requirement already satisfied: nltk in /Users/isabelsaludares/miniconda3/lib/python3.7/site-packages (3.5)\n",
      "Requirement already satisfied: click in /Users/isabelsaludares/miniconda3/lib/python3.7/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: tqdm in /Users/isabelsaludares/miniconda3/lib/python3.7/site-packages (from nltk) (4.42.1)\n",
      "Requirement already satisfied: regex in /Users/isabelsaludares/miniconda3/lib/python3.7/site-packages (from nltk) (2020.7.14)\n",
      "Requirement already satisfied: joblib in /Users/isabelsaludares/miniconda3/lib/python3.7/site-packages (from nltk) (0.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/isabelsaludares/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "import nltk\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stemmer = SnowballStemmer('english') # added"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Load stop words for Filipino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['akin',\n",
       " 'aking',\n",
       " 'ako',\n",
       " 'alin',\n",
       " 'am',\n",
       " 'amin',\n",
       " 'aming',\n",
       " 'ang',\n",
       " 'ano',\n",
       " 'anumang',\n",
       " 'apat',\n",
       " 'at',\n",
       " 'atin',\n",
       " 'ating',\n",
       " 'ay',\n",
       " 'ba',\n",
       " 'bababa',\n",
       " 'bago',\n",
       " 'bakit',\n",
       " 'bawat',\n",
       " 'bilang',\n",
       " 'dahil',\n",
       " 'dalawa',\n",
       " 'dapat',\n",
       " 'din',\n",
       " 'dito',\n",
       " 'doon',\n",
       " 'gagawin',\n",
       " 'gayunman',\n",
       " 'ginagawa',\n",
       " 'ginawa',\n",
       " 'ginawang',\n",
       " 'gumawa',\n",
       " 'gusto',\n",
       " 'habang',\n",
       " 'hanggang',\n",
       " 'hindi',\n",
       " 'huwag',\n",
       " 'iba',\n",
       " 'ibaba',\n",
       " 'ibabaw',\n",
       " 'ibig',\n",
       " 'ikaw',\n",
       " 'ilagay',\n",
       " 'ilalim',\n",
       " 'ilan',\n",
       " 'inyong',\n",
       " 'isa',\n",
       " 'isang',\n",
       " 'itaas',\n",
       " 'ito',\n",
       " 'iyo',\n",
       " 'iyon',\n",
       " 'iyong',\n",
       " 'ka',\n",
       " 'kahit',\n",
       " 'kailangan',\n",
       " 'kailanman',\n",
       " 'kami',\n",
       " 'kanila',\n",
       " 'kanilang',\n",
       " 'kanino',\n",
       " 'kanya',\n",
       " 'kanyang',\n",
       " 'kapag',\n",
       " 'kapwa',\n",
       " 'karamihan',\n",
       " 'katiyakan',\n",
       " 'katulad',\n",
       " 'kay',\n",
       " 'kaya',\n",
       " 'kaysa',\n",
       " 'ko',\n",
       " 'kong',\n",
       " 'kulang',\n",
       " 'kumuha',\n",
       " 'kung',\n",
       " 'laban',\n",
       " 'lahat',\n",
       " 'lamang',\n",
       " 'likod',\n",
       " 'lima',\n",
       " 'maaari',\n",
       " 'maaaring',\n",
       " 'maging',\n",
       " 'mahusay',\n",
       " 'makita',\n",
       " 'marami',\n",
       " 'marapat',\n",
       " 'masyado',\n",
       " 'may',\n",
       " 'mayroon',\n",
       " 'mga',\n",
       " 'minsan',\n",
       " 'mismo',\n",
       " 'mula',\n",
       " 'muli',\n",
       " 'na',\n",
       " 'nabanggit',\n",
       " 'naging',\n",
       " 'nagkaroon',\n",
       " 'nais',\n",
       " 'nakita',\n",
       " 'naman',\n",
       " 'namin',\n",
       " 'nang',\n",
       " 'napaka',\n",
       " 'narito',\n",
       " 'nasaan',\n",
       " 'ng',\n",
       " 'ngayon',\n",
       " 'ngayong',\n",
       " 'ni',\n",
       " 'nila',\n",
       " 'nilang',\n",
       " 'nito',\n",
       " 'nitong',\n",
       " 'niya',\n",
       " 'niyang',\n",
       " 'noon',\n",
       " 'o',\n",
       " 'pa',\n",
       " 'paano',\n",
       " 'pababa',\n",
       " 'paggawa',\n",
       " 'pagitan',\n",
       " 'pagkakaroon',\n",
       " 'pagkatapos',\n",
       " 'palabas',\n",
       " 'pamamagitan',\n",
       " 'panahon',\n",
       " 'pangalawa',\n",
       " 'para',\n",
       " 'paraan',\n",
       " 'pareho',\n",
       " 'pataas',\n",
       " 'pero',\n",
       " 'po',\n",
       " 'pumunta',\n",
       " 'pumupunta',\n",
       " 'sa',\n",
       " 'saan',\n",
       " 'sabi',\n",
       " 'sabihin',\n",
       " 'sarili',\n",
       " 'si',\n",
       " 'sila',\n",
       " 'sina',\n",
       " 'sino',\n",
       " 'siya',\n",
       " 'tatlo',\n",
       " 'tayo',\n",
       " 'tulad',\n",
       " 'tungkol',\n",
       " 'una',\n",
       " 'walang',\n",
       " 'yung']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stop words for Filipino\n",
    "dff=pd.read_csv('./data/nlp/survey/stopwords_tl.txt',sep='\\t',names=['stopword'],dtype=str)\n",
    "stop_filipino=list(dff['stopword'].values)\n",
    "stop_filipino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. stop words = stop words for English + stop words for Filipino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_english = list(gensim.parsing.preprocessing.STOPWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = frozenset(stop_english + \n",
    "                     stop_filipino + \n",
    "                     ['us','none','n/a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess texts\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in stop_words and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 processed docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image taken from [Sejal Dua Medium Page](https://towardsdatascience.com/nlp-preprocessing-and-latent-dirichlet-allocation-lda-topic-modeling-with-gensim-713d516c6c7d)\n",
    "<div>\n",
    "<img src=\"topic_model_illus.png\" width=\"600\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = l_dataset['Comments'].map(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4. Bag of Words on the Data set\n",
    "We then create a dictionary from `processed_docs` containing the number of times a word appears in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 announc\n",
      "1 import\n",
      "2 bayanihan\n",
      "3 center\n",
      "4 doktor\n",
      "5 initi\n",
      "6 konsulta\n",
      "7 launch\n",
      "8 messag\n",
      "9 miyerkul\n",
      "10 natin\n",
      "11 noong\n",
      "12 overwhelm\n",
      "13 pati\n",
      "14 posit\n",
      "15 respons\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 15:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embeddings\n",
    "- a technique of word representation that allows words with similar meaning to be understood by machine learning algorithms\n",
    "- it is a mapping of words into vectors of real numbers\n",
    "- this can be computed/mapped via: neural network, probabilistic model, or dimension reduction on word co-occurrence matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Techniques (some)\n",
    "reference: [Rabeh Ayari Medium Page](https://towardsdatascience.com/nlp-embedding-techniques-51b7e6ec9f92)\n",
    "#### 1. Bag-of-Words (BOW)\n",
    "\n",
    "- text is represented as a bag containing plenty of words\n",
    "- grammar and word order are neglected while the frequency is kept the same\n",
    "- feature generated by bag-of-words is a vector where n is the number of words in the input documents vocabulary\n",
    "\n",
    "#### 2. Term Frequency-Inverse Document Frequency\n",
    "\n",
    "- words are given importance (represented as weights) by TF-IDF importance instead of only frequency\n",
    "- statistical measure to evaluate the importance of words with respect to the document in a collection \n",
    "    - many commonly used words for each dataset that appear many times in the document but do not provide any important information. \n",
    "    - higher weight for higher number of occurences on the word in the document collection, in realtion to the whole corpus, therefore higher weights are attributed if the term is more EXCLUSIVELY used for that DOCUMENT CATEGORY\n",
    "\n",
    "#### 3. Word2Vec\n",
    "\n",
    "- one of the most efficient techniques\n",
    "- learned model: computationally efficient predictive model for learning word embeddings from raw text\n",
    "- plots the words in a multi-dimensional vector space, where similar words tend to be close to each other, surrounding words of a word provide the context to that word\n",
    "\n",
    "#### 4. Doc2Vec\n",
    "\n",
    "- creates an embedding of a document irrespective to its length\n",
    "- computes a feature vector for every document in the corpus\n",
    "- Doc2vec model is based on Word2Vec, with only adding another vector (paragraph ID) to the input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5. Gensim doc2bow\n",
    "We create a dictionary for each document; this contains how many words and how many times those words appear. <br>\n",
    "We save this to `bow_corpus`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 0 (\"announc\") appears 1 time.\n",
      "Word 1 (\"import\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "# sample output for the first document\n",
    "bow_doc_0=bow_corpus[0]\n",
    "for i in range(len(bow_doc_0)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_0[i][0], dictionary[bow_doc_0[i][0]], bow_doc_0[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6. TF-IDF\n",
    "Create tf-idf model object using models.TfidfModel on ‘bow_corpus’ and save it to ‘tfidf’, then apply transformation to the entire corpus and call it ‘corpus_tfidf’. Finally we preview TF-IDF scores for our first document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.6569394759215659), (1, 0.7539433168189094)]\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "from pprint import pprint\n",
    "for doc in corpus_tfidf: # preview TF-IDF scores for the first document\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7. LDA using Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.7.1. num of topics = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=5, id2word=dictionary, passes=2, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.027*\"test\" + 0.020*\"trace\" + 0.014*\"contact\" + 0.013*\"immedi\" + 0.013*\"posit\" + 0.011*\"antigen\" + 0.010*\"swab\" + 0.008*\"symptom\" + 0.008*\"join\" + 0.008*\"suggest\"\n",
      "Topic: 1 \n",
      "Words: 0.017*\"volunt\" + 0.010*\"natin\" + 0.010*\"sobrang\" + 0.010*\"overwhelm\" + 0.009*\"help\" + 0.007*\"medic\" + 0.007*\"request\" + 0.007*\"inspir\" + 0.007*\"amid\" + 0.006*\"lang\"\n",
      "Topic: 2 \n",
      "Words: 0.036*\"test\" + 0.013*\"posit\" + 0.013*\"covid\" + 0.010*\"need\" + 0.009*\"isol\" + 0.008*\"area\" + 0.007*\"number\" + 0.007*\"swab\" + 0.007*\"natin\" + 0.006*\"lang\"\n",
      "Topic: 3 \n",
      "Words: 0.020*\"isol\" + 0.014*\"vaccin\" + 0.012*\"test\" + 0.011*\"need\" + 0.008*\"work\" + 0.007*\"hope\" + 0.006*\"number\" + 0.006*\"help\" + 0.006*\"posit\" + 0.006*\"swab\"\n",
      "Topic: 4 \n",
      "Words: 0.049*\"test\" + 0.018*\"posit\" + 0.014*\"peopl\" + 0.011*\"malabon\" + 0.010*\"communiti\" + 0.008*\"health\" + 0.007*\"year\" + 0.007*\"isol\" + 0.007*\"natin\" + 0.007*\"thank\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.8. LDA using TF-IDF\n",
    "#### 4.8.1. num of topics = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.006*\"announc\" + 0.005*\"medic\" + 0.005*\"test\" + 0.004*\"natin\" + 0.004*\"maram\" + 0.004*\"trace\" + 0.004*\"packag\" + 0.004*\"contact\" + 0.004*\"salamat\" + 0.004*\"immedi\"\n",
      "Topic: 1 Word: 0.012*\"test\" + 0.009*\"posit\" + 0.006*\"hope\" + 0.006*\"vaccin\" + 0.005*\"target\" + 0.005*\"area\" + 0.005*\"tabl\" + 0.005*\"rate\" + 0.005*\"number\" + 0.005*\"case\"\n",
      "Topic: 2 Word: 0.005*\"swab\" + 0.005*\"kayanatinph\" + 0.005*\"symptom\" + 0.005*\"cab\" + 0.004*\"display\" + 0.004*\"thank\" + 0.004*\"medic\" + 0.004*\"muna\" + 0.004*\"lang\" + 0.004*\"provid\"\n",
      "Topic: 3 Word: 0.007*\"individu\" + 0.007*\"join\" + 0.006*\"test\" + 0.006*\"prevent\" + 0.006*\"page\" + 0.005*\"text\" + 0.005*\"reintegr\" + 0.004*\"ulit\" + 0.004*\"free\" + 0.004*\"maram\"\n",
      "Topic: 4 Word: 0.014*\"test\" + 0.012*\"inocul\" + 0.010*\"isol\" + 0.008*\"trace\" + 0.007*\"sunday\" + 0.007*\"center\" + 0.006*\"immedi\" + 0.006*\"suggest\" + 0.006*\"antigen\" + 0.005*\"swab\"\n"
     ]
    }
   ],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, \n",
    "                                             num_topics=5, \n",
    "                                             id2word=dictionary, \n",
    "                                             passes=2, \n",
    "                                             workers=4)\n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.9. check for a specific doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Comments\n",
      "0                             important announcement\n",
      "1  ini-launch natin noong miyerkules ang bayaniha...\n",
      "2  sobrang overwhelming ang support, at sobrang o...\n",
      "3  hindi kami nagpapigil kahit ang daming limitas...\n",
      "4  kaya, despite our reluctance to do so, tomorro...\n",
      "5  isang araw lang po ito. kailangan lang po nami...\n",
      "6  magreresume ulit tayo ng pagtanggap ng bagong ...\n",
      "7  humihingi ako ng paumanhin at pang-unawa sa la...\n",
      "8  gusto pa nating magpatuloy ang programa, at ma...\n",
      "9  naiimagine ko nga—kung kami na nag-o-augment l...\n"
     ]
    }
   ],
   "source": [
    "print(l_dataset[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.9.1. say we choose the one with index 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.8661197423934937\t \n",
      "Topic: 0.027*\"test\" + 0.020*\"trace\" + 0.014*\"contact\" + 0.013*\"immedi\" + 0.013*\"posit\" + 0.011*\"antigen\" + 0.010*\"swab\" + 0.008*\"symptom\" + 0.008*\"join\" + 0.008*\"suggest\"\n",
      "\n",
      "Score: 0.033656250685453415\t \n",
      "Topic: 0.020*\"isol\" + 0.014*\"vaccin\" + 0.012*\"test\" + 0.011*\"need\" + 0.008*\"work\" + 0.007*\"hope\" + 0.006*\"number\" + 0.006*\"help\" + 0.006*\"posit\" + 0.006*\"swab\"\n",
      "\n",
      "Score: 0.03350177779793739\t \n",
      "Topic: 0.049*\"test\" + 0.018*\"posit\" + 0.014*\"peopl\" + 0.011*\"malabon\" + 0.010*\"communiti\" + 0.008*\"health\" + 0.007*\"year\" + 0.007*\"isol\" + 0.007*\"natin\" + 0.007*\"thank\"\n",
      "\n",
      "Score: 0.03338038921356201\t \n",
      "Topic: 0.036*\"test\" + 0.013*\"posit\" + 0.013*\"covid\" + 0.010*\"need\" + 0.009*\"isol\" + 0.008*\"area\" + 0.007*\"number\" + 0.007*\"swab\" + 0.007*\"natin\" + 0.006*\"lang\"\n",
      "\n",
      "Score: 0.03334185108542442\t \n",
      "Topic: 0.017*\"volunt\" + 0.010*\"natin\" + 0.010*\"sobrang\" + 0.010*\"overwhelm\" + 0.009*\"help\" + 0.007*\"medic\" + 0.007*\"request\" + 0.007*\"inspir\" + 0.007*\"amid\" + 0.006*\"lang\"\n"
     ]
    }
   ],
   "source": [
    "ind=14\n",
    "for index, score in sorted(lda_model[bow_corpus[ind]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.8642151951789856\t \n",
      "Topic: 0.006*\"announc\" + 0.005*\"medic\" + 0.005*\"test\" + 0.004*\"natin\" + 0.004*\"maram\" + 0.004*\"trace\" + 0.004*\"packag\" + 0.004*\"contact\" + 0.004*\"salamat\" + 0.004*\"immedi\"\n",
      "\n",
      "Score: 0.03490997850894928\t \n",
      "Topic: 0.007*\"individu\" + 0.007*\"join\" + 0.006*\"test\" + 0.006*\"prevent\" + 0.006*\"page\" + 0.005*\"text\" + 0.005*\"reintegr\" + 0.004*\"ulit\" + 0.004*\"free\" + 0.004*\"maram\"\n",
      "\n",
      "Score: 0.03392622247338295\t \n",
      "Topic: 0.012*\"test\" + 0.009*\"posit\" + 0.006*\"hope\" + 0.006*\"vaccin\" + 0.005*\"target\" + 0.005*\"area\" + 0.005*\"tabl\" + 0.005*\"rate\" + 0.005*\"number\" + 0.005*\"case\"\n",
      "\n",
      "Score: 0.03352729603648186\t \n",
      "Topic: 0.014*\"test\" + 0.012*\"inocul\" + 0.010*\"isol\" + 0.008*\"trace\" + 0.007*\"sunday\" + 0.007*\"center\" + 0.006*\"immedi\" + 0.006*\"suggest\" + 0.006*\"antigen\" + 0.005*\"swab\"\n",
      "\n",
      "Score: 0.033421337604522705\t \n",
      "Topic: 0.005*\"swab\" + 0.005*\"kayanatinph\" + 0.005*\"symptom\" + 0.005*\"cab\" + 0.004*\"display\" + 0.004*\"thank\" + 0.004*\"medic\" + 0.004*\"muna\" + 0.004*\"lang\" + 0.004*\"provid\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model_tfidf[bow_corpus[ind]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fname_or_handle, separately, sep_limit, ignore, pickle_protocol)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0m_pickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"saved %s object\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: file must have a 'write' attribute",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-cd5ac64f5edb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlda_model_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lda_tfidf.model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fname, ignore, separately, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1569\u001b[0m         \"\"\"\n\u001b[1;32m   1570\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1571\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmart_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.state'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1572\u001b[0m         \u001b[0;31m# Save the dictionary separately if not in 'ignore'.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1573\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'id2word'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mignore\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fname_or_handle, separately, sep_limit, ignore, pickle_protocol)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"saved %s object\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# `fname_or_handle` does not have write attribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_smart_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseparately\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep_limit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36m_smart_save\u001b[0;34m(self, fname, separately, sep_limit, ignore, pickle_protocol)\u001b[0m\n\u001b[1;32m    556\u001b[0m                                        compress, subname)\n\u001b[1;32m    557\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m             \u001b[0mpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m             \u001b[0;31m# restore attribs handled specially\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36mpickle\u001b[0;34m(obj, fname, protocol)\u001b[0m\n\u001b[1;32m   1376\u001b[0m     \"\"\"\n\u001b[1;32m   1377\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfout\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# 'b' for binary, needed on Windows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1378\u001b[0;31m         \u001b[0m_pickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "lda_model_tfidf.save('lda_tfidf.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:failed to load state from lda_tfidf.model.state: Ran out of input\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get_lambda'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-0c2743b39cda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlda_loaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLdaMulticore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lda_tfidf.model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlda_loaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36mshow_topics\u001b[0;34m(self, num_topics, num_words, log, formatted)\u001b[0m\n\u001b[1;32m   1158\u001b[0m         \u001b[0mshown\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m         \u001b[0mtopic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_lambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1161\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchosen_topics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m             \u001b[0mtopic_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get_lambda'"
     ]
    }
   ],
   "source": [
    "lda_loaded = gensim.models.LdaMulticore.load('lda_tfidf.model')\n",
    "lda_loaded.show_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization using pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isabelsaludares/miniconda3/lib/python3.7/site-packages/sklearn/decomposition/_lda.py:28: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  EPS = np.finfo(np.float).eps\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No usable temporary directory found in ['/var/folders/ym/8xddr3cs4tzc0g3rm5n1rwhm0000gn/T/', '/tmp', '/var/tmp', '/usr/tmp', '/Users/isabelsaludares/Documents/Python']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-d6c933c66e6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mviz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgensim_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlda_model_tfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_tfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pyLDAvis/gensim_models.py\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(topic_model, corpus, dictionary, doc_topic_dist, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \"\"\"\n\u001b[1;32m    122\u001b[0m     \u001b[0mopts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_extract_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_topic_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pyLDAvis/_prepare.py\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(topic_term_dists, doc_topic_dists, doc_lengths, vocab, term_frequency, R, lambda_step, mds, n_jobs, plot_opts, sort_topics, start_index)\u001b[0m\n\u001b[1;32m    439\u001b[0m     topic_info = _topic_info(topic_term_dists, topic_proportion,\n\u001b[1;32m    440\u001b[0m                              \u001b[0mterm_frequency\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterm_topic_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m                              n_jobs, start_index)\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0mtoken_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_token_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterm_topic_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterm_frequency\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0mtopic_coordinates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_topic_coordinates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_term_dists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_proportion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pyLDAvis/_prepare.py\u001b[0m in \u001b[0;36m_topic_info\u001b[0;34m(topic_term_dists, topic_proportion, term_frequency, term_topic_freq, vocab, lambda_step, R, n_jobs, start_index)\u001b[0m\n\u001b[1;32m    276\u001b[0m     top_terms = pd.concat(Parallel(n_jobs=n_jobs)\n\u001b[1;32m    277\u001b[0m                           (delayed(_find_relevance_chunks)(log_ttd, log_lift, R, ls)\n\u001b[0;32m--> 278\u001b[0;31m                           for ls in _job_chunks(lambda_seq, n_jobs)))\n\u001b[0m\u001b[1;32m    279\u001b[0m     \u001b[0mtopic_dfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_top_term_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_terms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdefault_term_info\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_dfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m             \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m             \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_effective_n_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_initialize_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m             n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,\n\u001b[0;32m--> 722\u001b[0;31m                                              **self._backend_args)\n\u001b[0m\u001b[1;32m    723\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_timeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m                 warnings.warn(\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mconfigure\u001b[0;34m(self, n_jobs, parallel, prefer, require, idle_worker_timeout, **memmappingexecutor_args)\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midle_worker_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0menv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_worker_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m             context_id=parallel._id, **memmappingexecutor_args)\n\u001b[0m\u001b[1;32m    498\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/joblib/executor.py\u001b[0m in \u001b[0;36mget_memmapping_executor\u001b[0;34m(n_jobs, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_memmapping_executor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mMemmappingExecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_memmapping_executor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/joblib/executor.py\u001b[0m in \u001b[0;36mget_memmapping_executor\u001b[0;34m(cls, n_jobs, timeout, initializer, initargs, env, temp_folder, context_id, **backend_args)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0m_executor_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecutor_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mmanager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTemporaryResourcesManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# reducers access the temporary folder in which to store temporary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/joblib/_memmapping_reducer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, temp_folder_root, context_id)\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0;31m# exposes exposes too many low-level details.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mcontext_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muuid4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_current_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_current_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/joblib/_memmapping_reducer.py\u001b[0m in \u001b[0;36mset_current_context\u001b[0;34m(self, context_id)\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_current_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_context_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_new_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_new_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/joblib/_memmapping_reducer.py\u001b[0m in \u001b[0;36mregister_new_context\u001b[0;34m(self, context_id)\u001b[0m\n\u001b[1;32m    556\u001b[0m             )\n\u001b[1;32m    557\u001b[0m             new_folder_path, _ = _get_temp_dir(\n\u001b[0;32m--> 558\u001b[0;31m                 \u001b[0mnew_folder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_temp_folder_root\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m             )\n\u001b[1;32m    560\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_folder_finalizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_folder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/joblib/_memmapping_reducer.py\u001b[0m in \u001b[0;36m_get_temp_dir\u001b[0;34m(pool_folder_name, temp_folder)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtemp_folder\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;31m# Fallback to the default tmp folder, typically /tmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtemp_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgettempdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0mtemp_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0mpool_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_folder_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/tempfile.py\u001b[0m in \u001b[0;36mgettempdir\u001b[0;34m()\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtempdir\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m                 \u001b[0mtempdir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_default_tempdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0m_once_lock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/tempfile.py\u001b[0m in \u001b[0;36m_get_default_tempdir\u001b[0;34m()\u001b[0m\n\u001b[1;32m    227\u001b[0m     raise FileNotFoundError(_errno.ENOENT,\n\u001b[1;32m    228\u001b[0m                             \u001b[0;34m\"No usable temporary directory found in %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m                             dirlist)\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0m_name_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No usable temporary directory found in ['/var/folders/ym/8xddr3cs4tzc0g3rm5n1rwhm0000gn/T/', '/tmp', '/var/tmp', '/usr/tmp', '/Users/isabelsaludares/Documents/Python']"
     ]
    }
   ],
   "source": [
    "#!python -m pip install -U pyLDAvis\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "viz = pyLDAvis.gensim_models.prepare(lda_model_tfidf, corpus_tfidf, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isabelsaludares/miniconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'viz' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-c48e3cbff41e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mviz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'viz' is not defined"
     ]
    }
   ],
   "source": [
    "pyLDAvis.display(viz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Save viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isabelsaludares/miniconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'viz' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-fff511ce15dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mviz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'leni.html'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'viz' is not defined"
     ]
    }
   ],
   "source": [
    "pyLDAvis.save_html(viz, 'leni.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isabel.saludares@neuralmechanics.net"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
